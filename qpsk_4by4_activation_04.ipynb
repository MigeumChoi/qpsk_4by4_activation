{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOFxtY9RhAknXdHdoOPtIH4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cg_bkrVH1n2_","executionInfo":{"status":"ok","timestamp":1695620264494,"user_tz":-540,"elapsed":20420,"user":{"displayName":"최미금","userId":"03270121767541003919"}},"outputId":"1eaa4a21-8ff3-472d-ab28-48130daa99e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3593\n","Epoch 1: val_loss improved from inf to 0.34099, saving model to hl5_0100.h5\n","1/1 [==============================] - 1s 1s/step - loss: 0.3593 - val_loss: 0.3410\n","Epoch 2/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3470\n","Epoch 2: val_loss improved from 0.34099 to 0.32989, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 58ms/step - loss: 0.3470 - val_loss: 0.3299\n","Epoch 3/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3351\n","Epoch 3: val_loss improved from 0.32989 to 0.31914, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 69ms/step - loss: 0.3351 - val_loss: 0.3191\n","Epoch 4/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3235"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4: val_loss improved from 0.31914 to 0.30864, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 0.3235 - val_loss: 0.3086\n","Epoch 5/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3120\n","Epoch 5: val_loss improved from 0.30864 to 0.29833, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 66ms/step - loss: 0.3120 - val_loss: 0.2983\n","Epoch 6/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.3007\n","Epoch 6: val_loss improved from 0.29833 to 0.28822, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.3007 - val_loss: 0.2882\n","Epoch 7/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2897\n","Epoch 7: val_loss improved from 0.28822 to 0.27823, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 0.2897 - val_loss: 0.2782\n","Epoch 8/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2789\n","Epoch 8: val_loss improved from 0.27823 to 0.26847, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 68ms/step - loss: 0.2789 - val_loss: 0.2685\n","Epoch 9/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2682\n","Epoch 9: val_loss improved from 0.26847 to 0.25888, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 0.2682 - val_loss: 0.2589\n","Epoch 10/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2577\n","Epoch 10: val_loss improved from 0.25888 to 0.24946, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 59ms/step - loss: 0.2577 - val_loss: 0.2495\n","Epoch 11/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2474\n","Epoch 11: val_loss improved from 0.24946 to 0.24019, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.2474 - val_loss: 0.2402\n","Epoch 12/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2371\n","Epoch 12: val_loss improved from 0.24019 to 0.23110, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.2371 - val_loss: 0.2311\n","Epoch 13/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2270\n","Epoch 13: val_loss improved from 0.23110 to 0.22214, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 58ms/step - loss: 0.2270 - val_loss: 0.2221\n","Epoch 14/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2169\n","Epoch 14: val_loss improved from 0.22214 to 0.21328, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.2169 - val_loss: 0.2133\n","Epoch 15/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.2070\n","Epoch 15: val_loss improved from 0.21328 to 0.20461, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.2070 - val_loss: 0.2046\n","Epoch 16/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1972\n","Epoch 16: val_loss improved from 0.20461 to 0.19613, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 68ms/step - loss: 0.1972 - val_loss: 0.1961\n","Epoch 17/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1876\n","Epoch 17: val_loss improved from 0.19613 to 0.18783, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.1876 - val_loss: 0.1878\n","Epoch 18/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1782\n","Epoch 18: val_loss improved from 0.18783 to 0.17975, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 0.1782 - val_loss: 0.1798\n","Epoch 19/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1692\n","Epoch 19: val_loss improved from 0.17975 to 0.17189, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 68ms/step - loss: 0.1692 - val_loss: 0.1719\n","Epoch 20/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1603\n","Epoch 20: val_loss improved from 0.17189 to 0.16427, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 61ms/step - loss: 0.1603 - val_loss: 0.1643\n","Epoch 21/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1517\n","Epoch 21: val_loss improved from 0.16427 to 0.15687, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 60ms/step - loss: 0.1517 - val_loss: 0.1569\n","Epoch 22/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1433\n","Epoch 22: val_loss improved from 0.15687 to 0.14972, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.1433 - val_loss: 0.1497\n","Epoch 23/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1352\n","Epoch 23: val_loss improved from 0.14972 to 0.14285, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 0.1352 - val_loss: 0.1429\n","Epoch 24/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1275\n","Epoch 24: val_loss improved from 0.14285 to 0.13627, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 76ms/step - loss: 0.1275 - val_loss: 0.1363\n","Epoch 25/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1200\n","Epoch 25: val_loss improved from 0.13627 to 0.12999, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 67ms/step - loss: 0.1200 - val_loss: 0.1300\n","Epoch 26/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1128\n","Epoch 26: val_loss improved from 0.12999 to 0.12399, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 63ms/step - loss: 0.1128 - val_loss: 0.1240\n","Epoch 27/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.1060\n","Epoch 27: val_loss improved from 0.12399 to 0.11832, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 0.1060 - val_loss: 0.1183\n","Epoch 28/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0994\n","Epoch 28: val_loss improved from 0.11832 to 0.11295, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 62ms/step - loss: 0.0994 - val_loss: 0.1130\n","Epoch 29/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0932\n","Epoch 29: val_loss improved from 0.11295 to 0.10792, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 61ms/step - loss: 0.0932 - val_loss: 0.1079\n","Epoch 30/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0874\n","Epoch 30: val_loss improved from 0.10792 to 0.10322, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 61ms/step - loss: 0.0874 - val_loss: 0.1032\n","Epoch 31/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0819\n","Epoch 31: val_loss improved from 0.10322 to 0.09883, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 61ms/step - loss: 0.0819 - val_loss: 0.0988\n","Epoch 32/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0768\n","Epoch 32: val_loss improved from 0.09883 to 0.09477, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 88ms/step - loss: 0.0768 - val_loss: 0.0948\n","Epoch 33/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0721\n","Epoch 33: val_loss improved from 0.09477 to 0.09101, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 105ms/step - loss: 0.0721 - val_loss: 0.0910\n","Epoch 34/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0676\n","Epoch 34: val_loss improved from 0.09101 to 0.08755, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 83ms/step - loss: 0.0676 - val_loss: 0.0876\n","Epoch 35/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0635\n","Epoch 35: val_loss improved from 0.08755 to 0.08438, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 89ms/step - loss: 0.0635 - val_loss: 0.0844\n","Epoch 36/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0597\n","Epoch 36: val_loss improved from 0.08438 to 0.08149, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 90ms/step - loss: 0.0597 - val_loss: 0.0815\n","Epoch 37/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0562\n","Epoch 37: val_loss improved from 0.08149 to 0.07886, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 96ms/step - loss: 0.0562 - val_loss: 0.0789\n","Epoch 38/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0530\n","Epoch 38: val_loss improved from 0.07886 to 0.07648, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 85ms/step - loss: 0.0530 - val_loss: 0.0765\n","Epoch 39/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0501\n","Epoch 39: val_loss improved from 0.07648 to 0.07434, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0501 - val_loss: 0.0743\n","Epoch 40/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0474\n","Epoch 40: val_loss improved from 0.07434 to 0.07241, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 76ms/step - loss: 0.0474 - val_loss: 0.0724\n","Epoch 41/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0450\n","Epoch 41: val_loss improved from 0.07241 to 0.07069, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 78ms/step - loss: 0.0450 - val_loss: 0.0707\n","Epoch 42/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0428\n","Epoch 42: val_loss improved from 0.07069 to 0.06916, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 91ms/step - loss: 0.0428 - val_loss: 0.0692\n","Epoch 43/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0408\n","Epoch 43: val_loss improved from 0.06916 to 0.06780, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 90ms/step - loss: 0.0408 - val_loss: 0.0678\n","Epoch 44/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0390\n","Epoch 44: val_loss improved from 0.06780 to 0.06660, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 92ms/step - loss: 0.0390 - val_loss: 0.0666\n","Epoch 45/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0375\n","Epoch 45: val_loss improved from 0.06660 to 0.06555, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 80ms/step - loss: 0.0375 - val_loss: 0.0656\n","Epoch 46/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0360\n","Epoch 46: val_loss improved from 0.06555 to 0.06464, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 89ms/step - loss: 0.0360 - val_loss: 0.0646\n","Epoch 47/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0348\n","Epoch 47: val_loss improved from 0.06464 to 0.06384, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 106ms/step - loss: 0.0348 - val_loss: 0.0638\n","Epoch 48/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0336\n","Epoch 48: val_loss improved from 0.06384 to 0.06315, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 105ms/step - loss: 0.0336 - val_loss: 0.0632\n","Epoch 49/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0326\n","Epoch 49: val_loss improved from 0.06315 to 0.06256, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 84ms/step - loss: 0.0326 - val_loss: 0.0626\n","Epoch 50/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0318\n","Epoch 50: val_loss improved from 0.06256 to 0.06205, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 81ms/step - loss: 0.0318 - val_loss: 0.0621\n","Epoch 51/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0310\n","Epoch 51: val_loss improved from 0.06205 to 0.06162, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 92ms/step - loss: 0.0310 - val_loss: 0.0616\n","Epoch 52/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0303\n","Epoch 52: val_loss improved from 0.06162 to 0.06126, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 116ms/step - loss: 0.0303 - val_loss: 0.0613\n","Epoch 53/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0297\n","Epoch 53: val_loss improved from 0.06126 to 0.06096, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 115ms/step - loss: 0.0297 - val_loss: 0.0610\n","Epoch 54/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0291\n","Epoch 54: val_loss improved from 0.06096 to 0.06070, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 129ms/step - loss: 0.0291 - val_loss: 0.0607\n","Epoch 55/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0287\n","Epoch 55: val_loss improved from 0.06070 to 0.06050, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 101ms/step - loss: 0.0287 - val_loss: 0.0605\n","Epoch 56/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0282\n","Epoch 56: val_loss improved from 0.06050 to 0.06033, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 95ms/step - loss: 0.0282 - val_loss: 0.0603\n","Epoch 57/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0279\n","Epoch 57: val_loss improved from 0.06033 to 0.06019, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 90ms/step - loss: 0.0279 - val_loss: 0.0602\n","Epoch 58/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0275\n","Epoch 58: val_loss improved from 0.06019 to 0.06009, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 98ms/step - loss: 0.0275 - val_loss: 0.0601\n","Epoch 59/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0273\n","Epoch 59: val_loss improved from 0.06009 to 0.06001, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 91ms/step - loss: 0.0273 - val_loss: 0.0600\n","Epoch 60/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0270\n","Epoch 60: val_loss improved from 0.06001 to 0.05994, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 97ms/step - loss: 0.0270 - val_loss: 0.0599\n","Epoch 61/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0268\n","Epoch 61: val_loss improved from 0.05994 to 0.05990, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0268 - val_loss: 0.0599\n","Epoch 62/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0266\n","Epoch 62: val_loss improved from 0.05990 to 0.05988, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 98ms/step - loss: 0.0266 - val_loss: 0.0599\n","Epoch 63/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0264\n","Epoch 63: val_loss improved from 0.05988 to 0.05986, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 99ms/step - loss: 0.0264 - val_loss: 0.0599\n","Epoch 64/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0263\n","Epoch 64: val_loss improved from 0.05986 to 0.05986, saving model to hl5_0100.h5\n","1/1 [==============================] - 0s 104ms/step - loss: 0.0263 - val_loss: 0.0599\n","Epoch 65/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0262\n","Epoch 65: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 56ms/step - loss: 0.0262 - val_loss: 0.0599\n","Epoch 66/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0260\n","Epoch 66: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 57ms/step - loss: 0.0260 - val_loss: 0.0599\n","Epoch 67/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0259\n","Epoch 67: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 66ms/step - loss: 0.0259 - val_loss: 0.0599\n","Epoch 68/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0258\n","Epoch 68: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 64ms/step - loss: 0.0258 - val_loss: 0.0599\n","Epoch 69/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0258\n","Epoch 69: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 69ms/step - loss: 0.0258 - val_loss: 0.0599\n","Epoch 70/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0257\n","Epoch 70: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 56ms/step - loss: 0.0257 - val_loss: 0.0600\n","Epoch 71/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0256\n","Epoch 71: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 77ms/step - loss: 0.0256 - val_loss: 0.0600\n","Epoch 72/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0256\n","Epoch 72: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 69ms/step - loss: 0.0256 - val_loss: 0.0601\n","Epoch 73/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0255\n","Epoch 73: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0255 - val_loss: 0.0601\n","Epoch 74/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0254\n","Epoch 74: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0254 - val_loss: 0.0601\n","Epoch 75/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0254\n","Epoch 75: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0254 - val_loss: 0.0602\n","Epoch 76/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0254\n","Epoch 76: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0254 - val_loss: 0.0602\n","Epoch 77/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0253\n","Epoch 77: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0253 - val_loss: 0.0602\n","Epoch 78/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0253\n","Epoch 78: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0253 - val_loss: 0.0603\n","Epoch 79/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0252\n","Epoch 79: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0252 - val_loss: 0.0603\n","Epoch 80/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0252\n","Epoch 80: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0252 - val_loss: 0.0604\n","Epoch 81/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0252\n","Epoch 81: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 38ms/step - loss: 0.0252 - val_loss: 0.0604\n","Epoch 82/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0252\n","Epoch 82: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0252 - val_loss: 0.0604\n","Epoch 83/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0251\n","Epoch 83: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0251 - val_loss: 0.0605\n","Epoch 84/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0251\n","Epoch 84: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0251 - val_loss: 0.0605\n","Epoch 85/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0251\n","Epoch 85: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0251 - val_loss: 0.0606\n","Epoch 86/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 86: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0250 - val_loss: 0.0606\n","Epoch 87/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 87: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0250 - val_loss: 0.0606\n","Epoch 88/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 88: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0250 - val_loss: 0.0607\n","Epoch 89/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 89: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0250 - val_loss: 0.0607\n","Epoch 90/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0250\n","Epoch 90: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0250 - val_loss: 0.0607\n","Epoch 91/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0249\n","Epoch 91: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0249 - val_loss: 0.0608\n","Epoch 92/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0249\n","Epoch 92: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0249 - val_loss: 0.0608\n","Epoch 93/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0249\n","Epoch 93: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0249 - val_loss: 0.0609\n","Epoch 94/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0249\n","Epoch 94: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0249 - val_loss: 0.0609\n","Epoch 95/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0248\n","Epoch 95: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0248 - val_loss: 0.0609\n","Epoch 96/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0248\n","Epoch 96: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0248 - val_loss: 0.0610\n","Epoch 97/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0248\n","Epoch 97: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0248 - val_loss: 0.0610\n","Epoch 98/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0248\n","Epoch 98: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 38ms/step - loss: 0.0248 - val_loss: 0.0610\n","Epoch 99/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0248\n","Epoch 99: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0248 - val_loss: 0.0611\n","Epoch 100/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0247\n","Epoch 100: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0247 - val_loss: 0.0611\n","Epoch 101/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0247\n","Epoch 101: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0247 - val_loss: 0.0611\n","Epoch 102/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0247\n","Epoch 102: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 50ms/step - loss: 0.0247 - val_loss: 0.0612\n","Epoch 103/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0247\n","Epoch 103: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0247 - val_loss: 0.0612\n","Epoch 104/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0247\n","Epoch 104: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0247 - val_loss: 0.0612\n","Epoch 105/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0246\n","Epoch 105: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0246 - val_loss: 0.0613\n","Epoch 106/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0246\n","Epoch 106: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0246 - val_loss: 0.0613\n","Epoch 107/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0246\n","Epoch 107: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0246 - val_loss: 0.0613\n","Epoch 108/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0246\n","Epoch 108: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0246 - val_loss: 0.0614\n","Epoch 109/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0246\n","Epoch 109: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0246 - val_loss: 0.0614\n","Epoch 110/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0245\n","Epoch 110: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0245 - val_loss: 0.0614\n","Epoch 111/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0245\n","Epoch 111: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0245 - val_loss: 0.0615\n","Epoch 112/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0245\n","Epoch 112: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0245 - val_loss: 0.0615\n","Epoch 113/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0245\n","Epoch 113: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0245 - val_loss: 0.0615\n","Epoch 114/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0245\n","Epoch 114: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0245 - val_loss: 0.0616\n","Epoch 115/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 115: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 50ms/step - loss: 0.0244 - val_loss: 0.0616\n","Epoch 116/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 116: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0244 - val_loss: 0.0616\n","Epoch 117/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 117: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0244 - val_loss: 0.0616\n","Epoch 118/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 118: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0244 - val_loss: 0.0617\n","Epoch 119/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 119: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0244 - val_loss: 0.0617\n","Epoch 120/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0244\n","Epoch 120: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0244 - val_loss: 0.0617\n","Epoch 121/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 121: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0243 - val_loss: 0.0618\n","Epoch 122/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 122: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0243 - val_loss: 0.0618\n","Epoch 123/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 123: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0243 - val_loss: 0.0618\n","Epoch 124/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 124: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 45ms/step - loss: 0.0243 - val_loss: 0.0619\n","Epoch 125/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0243\n","Epoch 125: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0243 - val_loss: 0.0619\n","Epoch 126/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0242\n","Epoch 126: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0242 - val_loss: 0.0619\n","Epoch 127/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0242\n","Epoch 127: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0242 - val_loss: 0.0620\n","Epoch 128/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0242\n","Epoch 128: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0242 - val_loss: 0.0620\n","Epoch 129/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0242\n","Epoch 129: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0242 - val_loss: 0.0620\n","Epoch 130/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0242\n","Epoch 130: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 46ms/step - loss: 0.0242 - val_loss: 0.0621\n","Epoch 131/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0241\n","Epoch 131: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0241 - val_loss: 0.0621\n","Epoch 132/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0241\n","Epoch 132: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.0621\n","Epoch 133/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0241\n","Epoch 133: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 53ms/step - loss: 0.0241 - val_loss: 0.0622\n","Epoch 134/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0241\n","Epoch 134: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0241 - val_loss: 0.0622\n","Epoch 135/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0241\n","Epoch 135: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0241 - val_loss: 0.0622\n","Epoch 136/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0240\n","Epoch 136: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 50ms/step - loss: 0.0240 - val_loss: 0.0623\n","Epoch 137/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0240\n","Epoch 137: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0240 - val_loss: 0.0623\n","Epoch 138/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0240\n","Epoch 138: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0240 - val_loss: 0.0623\n","Epoch 139/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0240\n","Epoch 139: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0240 - val_loss: 0.0623\n","Epoch 140/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0240\n","Epoch 140: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0240 - val_loss: 0.0624\n","Epoch 141/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0239\n","Epoch 141: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 48ms/step - loss: 0.0239 - val_loss: 0.0624\n","Epoch 142/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0239\n","Epoch 142: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0239 - val_loss: 0.0624\n","Epoch 143/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0239\n","Epoch 143: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0239 - val_loss: 0.0625\n","Epoch 144/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0239\n","Epoch 144: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0239 - val_loss: 0.0625\n","Epoch 145/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0239\n","Epoch 145: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0239 - val_loss: 0.0625\n","Epoch 146/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 146: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0238 - val_loss: 0.0626\n","Epoch 147/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 147: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0238 - val_loss: 0.0626\n","Epoch 148/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 148: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0238 - val_loss: 0.0626\n","Epoch 149/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 149: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0238 - val_loss: 0.0627\n","Epoch 150/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 150: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 47ms/step - loss: 0.0238 - val_loss: 0.0627\n","Epoch 151/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0238\n","Epoch 151: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0238 - val_loss: 0.0627\n","Epoch 152/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0237\n","Epoch 152: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0237 - val_loss: 0.0628\n","Epoch 153/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0237\n","Epoch 153: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0237 - val_loss: 0.0628\n","Epoch 154/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0237\n","Epoch 154: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0237 - val_loss: 0.0628\n","Epoch 155/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0237\n","Epoch 155: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0237 - val_loss: 0.0629\n","Epoch 156/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0237\n","Epoch 156: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0237 - val_loss: 0.0629\n","Epoch 157/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0236\n","Epoch 157: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 43ms/step - loss: 0.0236 - val_loss: 0.0629\n","Epoch 158/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0236\n","Epoch 158: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 49ms/step - loss: 0.0236 - val_loss: 0.0630\n","Epoch 159/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0236\n","Epoch 159: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 42ms/step - loss: 0.0236 - val_loss: 0.0630\n","Epoch 160/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0236\n","Epoch 160: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 40ms/step - loss: 0.0236 - val_loss: 0.0630\n","Epoch 161/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0236\n","Epoch 161: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 41ms/step - loss: 0.0236 - val_loss: 0.0631\n","Epoch 162/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0235\n","Epoch 162: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 39ms/step - loss: 0.0235 - val_loss: 0.0631\n","Epoch 163/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0235\n","Epoch 163: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 65ms/step - loss: 0.0235 - val_loss: 0.0631\n","Epoch 164/3000\n","1/1 [==============================] - ETA: 0s - loss: 0.0235\n","Epoch 164: val_loss did not improve from 0.05986\n","1/1 [==============================] - 0s 44ms/step - loss: 0.0235 - val_loss: 0.0632\n","1/1 [==============================] - 0s 125ms/step - loss: 0.0788\n","loss_and_metrics : 0.07876123487949371\n","1/1 [==============================] - 0s 116ms/step\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import scipy\n","import numpy\n","import h5py\n","\n","#import tensorflow\n","from tensorflow import keras\n","\n","#print('scipy ' + scipy.__version__)\n","#print('numpy ' + numpy.__version__)\n","#print('h5py ' + h5py.__version__)\n","\n","#print('tensorflow ' + tensorflow.__version__)\n","#print('keras ' + keras.__version__)\n","\n","import scipy.io\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation\n","from keras.optimizers import SGD\n","from tensorflow.keras.optimizers import Adam\n","from keras.optimizers import Nadam\n","from keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.datasets import cifar10\n","#error발생: from tensorflow.keras.utils import np_utils\n","from tensorflow.keras.utils import to_categorical\n","\n","\n","train_x_data = scipy.io.loadmat('ml_detect_in_train.mat')\n","train_y_data = scipy.io.loadmat('ml_detect_out_train.mat')\n","\n","train_x = train_x_data['in']\n","train_y = train_y_data['out']\n","\n","\n","\n","val_x_data = scipy.io.loadmat('ml_detect_in_val.mat')\n","val_y_data = scipy.io.loadmat('ml_detect_out_val.mat')\n","\n","val_x = val_x_data['in']\n","val_y = val_y_data['out']\n","\n","\n","# relu, tanh, elu, selu\n","\n","model = Sequential()\n","model.add(Dense(units=100, input_dim=40, activation=\"selu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"selu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"selu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"selu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=100, activation=\"selu\", kernel_initializer=\"normal\"))\n","#model.add(Dropout(0.5))\n","model.add(Dense(units=4, activation=\"linear\", kernel_initializer='normal'))\n","\n","\n","#model.compile(loss='mean_squared_error', optimizer='adam')\n","#model.compile(loss='mean_squared_error', optimizer='adamax')\n","#model.compile(loss='mean_squared_error', optimizer='nadam')\n","#model.compile(loss='mean_squared_error', optimizer='rmsprop')\n","model.compile(loss='mean_squared_error', optimizer='sgd')\n","\n","#model.fit(train_x, train_y, epochs=1000, batch_size=32)\n","\n","from keras.callbacks import EarlyStopping\n","from keras.callbacks import ModelCheckpoint\n","early_stopping = EarlyStopping(patience = 100) # 조기종료 콜백함수 정의, 100 에포크 동안은 기다림\n","checkpoint_callback = ModelCheckpoint('hl5_0100.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","history = model.fit(train_x, train_y, epochs=3000, batch_size=32, validation_data=(val_x, val_y), callbacks=[early_stopping, checkpoint_callback])\n","\n","\n","from keras.models import load_model\n","model_cp = load_model('hl5_0100.h5')\n","\n","test_x_data = scipy.io.loadmat('ml_detect_in_test.mat')\n","test_y_data = scipy.io.loadmat('ml_detect_out_test.mat')\n","test_x = test_x_data['in']\n","test_y = test_y_data['out']\n","\n","loss_and_metrics = model_cp.evaluate(test_x, test_y, batch_size=32)\n","\n","print('loss_and_metrics : ' + str(loss_and_metrics))\n","\n","\n","yhat=model_cp.predict(test_x)\n","scipy.io.savemat('hl5_0500_pred.mat',dict([('predict_ch', yhat) ]))\n","\n","import matplotlib.pyplot as plt\n","import os\n","\n","y_vloss = history.history['val_loss']\n","y_loss = history.history['loss']\n","\n","x_len = numpy.arange(len(y_loss))\n","plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n","plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n","\n","plt.legend(loc='upper right')\n","plt.grid()\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.show()"]}]}